<!DOCTYPE html>
<html lang="en" class="light-theme">
  <head>
    <script>
      // Immediately set theme before anything else
      document.documentElement.className =
        localStorage.getItem("theme") === "dark" ? "dark-theme" : "light-theme";
    </script>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Generative AI Art</title>
    <link rel="stylesheet" href="/styles.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css"
    />
  </head>

  <body>
    <header>
      <a href="/" id="head-link">cobanov</a>
      <nav class="main-nav">
        <a href="/blog/" class="nav-link">Blog</a>
        <a href="/projects/" class="nav-link">Projects</a>
      </nav>
      <div class="header-right">
        <button id="theme-toggle" aria-label="Toggle dark mode">
          <i class="fas fa-moon"></i>
        </button>
        <div class="social-icons">
          <a
            href="https://github.com/cobanov"
            target="_blank"
            rel="noopener noreferrer"
            aria-label="GitHub"
          >
            <i class="fab fa-github"></i>
          </a>
          <a
            href="https://twitter.com/mertcobanov"
            target="_blank"
            rel="noopener noreferrer"
            aria-label="Twitter"
          >
            <i class="fab fa-twitter"></i>
          </a>
        </div>
      </div>
    </header>
    <main>
      <div class="post-date">2025-05-07</div>
      <h1>Generative AI Art</h1>

<p>Date: December 15, 2023<br />
Author: Mert Cobanov</p>

<hr />

<h2>Üretken Yapay Zeka Sanatı — Generative AI Art</h2>

<p>Üretken yapay zeka sanatı muhakkak ki son 5 yılın en ilginç konularından biri olurken, 2023'ün de en ehemmiyetli teknolojisi oldu. Dünya çapında yapay zeka geliştiricileri ile konservatif sanatçıları iki farklı kutba ayırırken, şirketlerin ve devletlerin yeni regülasyonlar konusunda mutabakat sağlamalarını zorunlu kıldı. Son kullanıcılar neyin yapay zeka ile oluşturulduğunu, neyin ise gerçek görüntü olduğunu ayırmakta zorluk çekiyor. Toplumun bir kısmı bu hızla gelişen teknoloji karşısında ürpertiye yakalanırken, kimi ise hemen adapte olup hayatına dahil ediyor. Sosyal medya hesaplarımızda, 16. yüzyılın en ünlü ressamlarından Jacques-Louis David gibi sanatçıların eserlerini andıran selfie’ler oluşturduk, yüzümüzü ünlü kişiliklerin yüzleriyle değiştirdik veya çizgi film karakterlerine büründük. Esasında, bugün ve gelecek dönemler için, gerçek ve sanal dünyada aynı anda bulunan varlıklara dönüştük.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*ZA-dye1xYL2ZabBmkfs2wQ.png" alt="image" /></p>

<p>Solda gercek tablo, sagda yapay zeka ile gercek sanat eserleriyle egitilmis model ciktisi</p>

<p>2023 yılı, yapay zekanın geçmiş on yıl içerisinde biriktirdiği kümülatif etkilerin zirveye ulaşarak hayatımızın her alanına nüfuz ettiği bir dönem oldu demek hiç de abartı sayılmaz. Günümüzde, neredeyse her şirket ürünlerine yapay zeka entegrasyonlarını eklemeyi arzuluyor. İnsanlar, akıllı telefonlarına hızla sorular sorup anında cevaplar alabilecekleri uygulamalar yüklüyorlar. Aynı zamanda, büyük teknoloji şirketleri de hedeflerini, yapay zeka odaklı teknolojilere yönlendiriyor. Bu gelişimlerin hem doğal dil, hem de görsel algılama tarafında ilerlemesinin tabii ki bir nedeni var. Bu teknolojik devrim, 2017 yılında <strong>Google</strong> tarafından yayınlanan <strong>“Attention Is All You Need”</strong> makalesi ve <strong>“Diffusion Mimarisi”</strong> olarak adlandırdığımız iki yenilikçi teknolojinin ortaya çıkışıyla mümkün oldu. Bu çalışmalar, yapay zekanın gelişimini hızlandıran ve onu günlük yaşamımızın vazgeçilmez bir parçası haline getiren temel taşlardır.</p>

<p><strong>Üretken sanat (generative art),</strong> 1960&#39;lı yıllardan bu yana hayatımızda önemli bir yer tutuyor. Bu dönemde, sanatın ilk temel ve basit örnekleri deneysel ve avant-garde bir pozisyonda yer alıyordu. 1960 ve 1965 yılları arasında, bu eserleri üreten sanatçılar, <strong>“üretken sanat”</strong> terimini, bilgisayarla oluşturulan geometrik şekiller ve algoritmik olarak üretilen çıktılar bağlamında kullanıyorlardı. Bu alanın öncülerinden biri ve eserleriyle çalışma fırsatı bulduğum <strong>Vera Molnar,</strong> 1924 doğumlu Macar bir medya sanatçısıydı ve ne yazık ki, 100 yaşına bir hafta kala, 2023 Aralık ayında aramızdan ayrıldı. Vera Molnar, üretken sanatın öncüsü olmasının yanı sıra, bu sanatsal eserlerin üretiminde bilgisayarı kullanan ilk kadınlardan biriydi. Onun çalışmaları, sanat ve teknolojinin kesişimindeki yenilikçi yaklaşımları temsil ediyor ve günümüzdeki dijital sanat anlayışının temellerini atıyor.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*rsmc-y8hXWz2dlfs-kJcYA.jpeg" alt="image" /></p>

<p><strong>Üretken sanat,</strong> ya da İngilizce adıyla generative art, var olduğu her dönemde sanat dünyasında karmaşa ve sansasyonel tartışmalara yol açmıştır. Bu sanat dalıyla ilgili akıllara gelen en temel sorulardan biri, bir eser ortaya çıktığında, eserin sahibinin kim olduğuyla ilgilidir: Bu eseri yaratan algoritmayı geliştiren yazılımcı mı, algoritmanın veya yapay zeka modelinin kendisi mi, yoksa eseri hayal eden ve kendi hikayesini, tarzını yansıtan sanatçı mı? Bu konu her zaman tartışmalı olmuştur. Geliştirilen yazılım veya yapay zeka modeli, bir bakıma sistemsel özerkliğe benzetilebilir. Bir yanda, fırça ve tuvali kullanarak ve sinirsel motor sistemlerine dayanarak eser yaratan insan sanatçı bulunurken, diğer yanda algoritmaları kuran, bunları şekillendiren ve bu yolla sanat üreten yazılımcılar bulunmaktadır. Bu, sanatın tanımı ve sınırları üzerine derinlemesine düşünmeye davet eden bir ikilemdir.</p>

<p>Bu hassas konuları geride bıraktığımızda, bugün geldiğimiz noktada, Turing testlerinden başarıyla geçebilen, bazen bizi ürküten, bazen de heyecanlandıran bir yapay zeka teknolojisine sahibiz. Bu eserleri oluşturmamızda büyük bir rol oynayan, arkasındaki büyüleyici matematiğe birazdan değineceğim. Elbette, bu gelişmelerin gerçekleşmesi, donanım ve yazılım teknolojilerinin bu kadar ilerlemesine bağlı. Ancak, bu sanat eserlerini üretmek için oldukça yüksek bilgisayar gücü gerekiyor. Eğer yüzlerce ekran kartı, güçlü işlemciler, iyi bir matematik ve istatistik bilgisine sahipseniz ve aynı zamanda sanatsal ve estetik bir ruha sahipseniz, üretken yapay zeka sanatı geliştiricisi olabilirsiniz. Bu, hem teknolojik hem de sanatsal yeteneklerin birleştiği, son derece özgün ve yenilikçi bir alandır.</p>

<h3>Üretken Yapay Zeka Sanatı</h3>

<p><strong>“Üretici yapay zeka”</strong> terimi, yazı, görsel, ses veya farklı formatlarda medya üretimi üzerine geliştirilen yapay zeka modellerini tanımlamak için kullanılır. Bu alana, günümüzde yaygın olarak kullanılan <strong>ChatGPT</strong> gibi yazı tabanlı soru-cevap yapay zeka teknolojileri de dahildir. Müzik, şiir veya edebiyat gibi alanlar sanatın önemli parçaları olmakla birlikte, teknolojinin gelişim süreci nedeniyle üretici yapay zeka sanatı, genellikle yanlış bir algı ile, özellikle görsel alanla ilişkilendirilir. Bu yazıda da, üretici yapay zeka sanatını esas olarak görsel bağlamda ele alacağım.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*5bKJmKkwCqGabiKixeqzlQ.png" alt="image" /></p>

<p>Modern Asian Ukiyoe Edo Style Art, Mert Cobanov, 2023.</p>

<p>Üretken sanatın ilk dönemlerinde, modeller genellikle daha basit matematiksel programlama teknikleri kullanılarak geliştiriliyordu. Bunlara ek olarak, robotik kollar, rastgele sayı üreteçleri ve çeşitli algoritmalar daha sık kullanılıyordu. Zamanla, görüntü işleme tekniklerinin gelişmesi ve bu tekniklerin derin öğrenme ile birleştirilmesi fikri, yapay zekanın sanat üretiminde daha etkin bir rol almasını sağladı. Bu gelişmeler, üretici yapay zeka sanatının bugünkü sofistike ve görsel olarak zengin formuna evrilmesine ön ayak oldu.</p>

<h3>AICAN</h3>

<p>Bu alandaki öncü örneklerden biri, Rutgers Üniversitesi’nde Dr. Ahmed Elgammal ve ekibi tarafından geliştirilen <strong>AICAN</strong> (Yapay Zeka Yaratıcı Rekabet Ağı) sistemidir. <strong>AICAN, Barok, Rokoko ve Soyut Dışavurumculuk</strong> gibi çeşitli sanat tarzları üzerine eğitilmiş bir üretken yapay zeka modelidir. Bu sistemin en dikkat çekici özelliklerinden biri, daha önce hiç görülmemiş yeni sanat tarzlarını keşfetme ve yaratma kabiliyetidir. Temel olarak, görsel üretmek için eğitilmiş bir yapay sinir ağının değişkenlerini manipüle ederek yeni görseller üretebilmek üzerine çalışır. Aşağıdaki görselde, AICAN sistemi tarafından yaratılan üretken bir yapay zeka sanat eserini görebilirsiniz.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*JpQuGey8sLjkpdvAtThS0Q.png" alt="image" /></p>

<p><strong>AICAN</strong>, yapay zekanın sanat dünyasındaki rolünü yeniden tanımlıyor ve geleneksel sanat anlayışlarını dönüştürerek sanatın geleceği üzerinde önemli bir etki yaratıyor. Bu sistem, teknoloji ve sanatın bir arada nasıl yeni estetik anlayışlar ve yaratıcı ifadeler üretebileceğinin somut bir örneğini sunmaktadır.</p>

<h3>CLIP</h3>

<p>OpenAI tarafından geliştirilen <strong>CLIP</strong>, yapay zeka mimarisi alanında önemli bir yenilik olarak karşımıza çıkıyor. Şu anda kullanılan birçok sanatsal model bu mimariyi temel alıyor. <strong>CLIP</strong>’in özelliği, görselleri ve bu görsellere ait tanımlamaları eşleştiren bir zeka modeline dayanmasıdır. Yani, yazı ve görsel içerikleri anlamsal bir bağlamda, ortak bir uzayda eşleştiriyor. Matematiksel bir uzayda tüm görselleri ve bunlara karşılık gelen tanımları bir matriste tanımlama yeteneğimiz bu model sayesinde mümkün hale gelmiştir. En etkileyici özelliği ise, metinden görsel üretime ve görselden metin oluşturmaya olanak sağlamasıdır. Bu, metin ve görsel içerikler arasında zengin ve karmaşık bir etkileşim kurabilmemizi sağlayan bir teknolojidir, böylece yapay zekanın yaratıcı potansiyelini yeni boyutlara taşımaktadır.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*G4nfyoMggMqWr1limfMFyQ.png" alt="image" /></p>

<h2>GANs</h2>

<p>GAN’ler, yani Üretken Çekişmeli Ağlar, temelde iki sinir ağından oluşan bir makine öğrenimi algoritması türüdür: bir üreteç ve bir ayırt edici. Üreteç ağı, eğitim veri setine benzer yeni veri örnekleri, örneğin görüntüler veya sesler üretirken; ayırt edici ağ, üretilen örnekler ile gerçek olanları ayırt etmeyi öğrenir. Rekabetçi bir süreç aracılığıyla, iki ağ birbirleriyle yarışır, ta ki üreteç, ayırt ediciyi kandırabilecek gerçekçi örnekler üretene kadar.</p>

<p><strong>Üretken Çekişmeli Ağlar (GAN’ler)</strong> bağlamında, <strong>“örtük uzay” (latent space)</strong>, görüntüler veya diğer verileri üretmek için kullanılan giriş değişkenleridir. Bir GAN’da, üreteç ağı bir dizi gizli değişkeni girdi olarak alır ve bu değişkenlere dayanarak bir görüntü veya diğer veriler üretir. Ayırt edici ağ ise, üretilen çıktıyı değerlendirir ve üretecin çıktısını nasıl iyileştirebileceği konusunda geri bildirim sağlar.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*derj3c-g4omXq1sxCpZ0Ow.png" alt="image" /></p>

<p>Bir GAN’ı eğitmenin amacı, örtük uzay ile veri alanı arasındaki eşleşmeyi öğrenmektir, böylece üreteç ağı, belirli bir gizli değişken kümesine dayalı olarak gerçekçi ve yüksek kaliteli çıktılar üretebilir.</p>

<p>Ve sonrasında, bahsedilen gizli alanı kontrol etmek için kullanılabilecek yeni bir teknik geliştirildi. Bu teknik, <strong>GAN</strong> modelimizi yönetmek için daha önce bahsettiğim <strong>CLIP</strong> modelini kullanma fikriydi. Görüntüyle çıktıyı eşleştiren bir yapay zeka modelimiz zaten mevcuttu, artık görüntülerle eğittiğimiz yapay zeka modelimizi <strong>isteklerle (prompt)</strong> kontrol etmek son derece etkileyici bir gelişme oldu. Bu, kararlı difüzyon gibi bugün kullandığımız tüm tekniklerin temel yapı taşlarından biridir.</p>

<h2>Diffusion</h2>

<p>Ve artık, üretken yapay zeka sanatının altın çağını başlatan devrimsel bir mimariye ulaştığımızı söyleyebiliriz. Muhtemelen son zamanlarda Twitter’da veya diğer sosyal medya platformlarında, <strong>Midjourney</strong> veya <strong>Stable Diffusion</strong> gibi araçlarla, fikirlerinizi veya hayallerinizi basit bir cümleyle (istem veya prompt) hayata geçiren görsellerle karşılaşmışsınızdır.</p>

<p>Aslında bu tür çalışmalar, <strong>“Latent Diffusion”</strong> ya da Türkçesiyle <strong>“Örtük Yayılım”</strong> adı verilen bir yapay zeka mimarisinin bir ürünüdür. Örtük yayılım modelleri, eğitim görüntülerinin istatistiksel dağılımını öğrenerek ve bu dağılımı yeni, benzersiz görüntüler oluşturmak için kullanarak çalışır. Bu yapay zeka modelleri, milyarlarca fotoğraf ve bunlara eşlik eden açıklamaları öğrenerek yeni görseller yaratmanıza olanak tanır. Model eğitildikten sonra, öğrenilen dağılımdan örnekleme yoluyla yeni, benzersiz görseller oluşturmak mümkündür.</p>

<p>Bu örnekleme süreci, modelin örtük uzayında, bir görüntüyü tanımlayan benzersiz özellikler setine karşılık gelen rastgele bir noktanın seçilmesini içerir. Model, örtük uzaydaki farklı noktalara dayanarak görseller üretir ve böylece, stil ve içerik açısından orijinal eğitim görüntülerine benzeyen, farklı görüntüler yaratır. Bu karmaşık süreci, sadece hayal gücünüzü yazıya dökerek (CLIP modelinde kullandığımız gibi) kontrol edebilirsiniz, bu da sanatsal ifade ve teknolojinin kesişim noktasında yeni ufuklar açar.</p>

<h3>Teorik</h3>

<p><strong>Stable Diffusion</strong> modeli, görüntü oluşturma sürecinde bir dizi karmaşık bileşeni entegre eder. Bunlar arasında <strong>VAE (varyasyonel otoenkoder), Tokenizer ve Metin Kodlayıcı, UNet ve Zamanlayıcı (Scheduler)</strong> bulunmaktadır.</p>

<p>Diffüzyon sürecinin temel amacı, fotoğraflara yavaş yavaş gürültü eklemek ve her adımda modelin bu gürültüyü nasıl kaldıracağını öğrenmesini sağlamaktır. Modelin çıkarım aşamasında, verdiğimiz rastgele gürültü girdisini kaldırarak görsel oluşturmasını bekliyoruz. Gürültü ekleme süreci lineer olmayan bir şekilde gerçekleşir.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*SYoShcfjQaIMYrIYrumehg.png" alt="image" /></p>

<p>Gürültü Zamanlaması (Noise Schedule), farklı zaman adımlarında ne kadar gürültü ekleneceğini belirler. Örneğin, ‘<strong>DDPM’ (“Denoising Diffusion Probabilistic Models”)</strong> makalesinde tanımlanan bir yaklaşım, gürültü ekleme sürecini açıklamaktadır.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*sCIJeF22AiiM2zYEtj_jRw.jpeg" alt="image" /></p>

<p>Diffusion modelinde gürültü ekleme süreci lineer olarak gerçekleşmez. Lineer bir gürültü ekleme süreci, fotoğrafın hızlı bir şekilde tamamen gürültülü bir forma dönüşmesine neden olur. Bu nedenle, daha kontrollü bir gürültü ekleme süreci için kosinüs yaklaşımını kullanılır.</p>

<p><strong>Zamanlamacının iki temel görevi vardır:</strong></p>

<ul>
<li>Zamanlayıcı ile birlikte görüntüye iteratif olarak gürültü eklemek.</li>
<li>Fotoğraftaki gürültü kaldırılırken bir sonraki zaman adımında görüntünün nasıl güncelleneceğini belirlemek.</li>
</ul>

<p>Diffüzyon modellerinde, <strong>VAE</strong> kullanılır. Bu, görüntünün gizli bir uzayda daha küçük bir temsilini sağlar. Örneğin, <strong>512x512x3</strong> boyutundaki bir görsel, <strong>64x64x4</strong> boyutuna indirgenir.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*ebcr3kjO9XqQnvrmFrOyIw.png" alt="image" /></p>

<p><strong>Metin Koşullandırması (Text Conditioning),</strong> diffüzyon modeli eğitilirken, görselin oluşumunda etkili olacak şekilde metin verilerinin de bilgi olarak eklenmesidir. Burada amaç, gürültülü bir görsel verildiğinde, modelin metne uygun bir şekilde gürültüyü çözmesi ve görselin buna göre oluşmasıdır.</p>

<p>Çıkarım anında, başlangıçta saf gürültü ve oluşturmak istediğimiz görsel ile uyumlu bir metin verilir ve modelin rastgele bir girdiyi metne göre oluşturması istenir. Metin koşullandırmasını oluşturmak için yine <strong>CLIP</strong> modeli kullanılır.</p>

<p><strong>Çapraz Dikkat(Cross Attention),</strong> modelin son çıktısı başlangıçta kullanılan gürültü girdisine oldukça bağlı olduğundan, bu durumu dengelemek için <strong>Classifier Free Guidance (Sınıflandırıcı Serbest Yönlendirme — CFG)</strong> adı verilen bir yöntem kullanılır. Kısaca, model eğitim sırasında metin bilgisi olmadan eğitilir, çıkarım anında ise sıfır koşullandırma ve metin koşullandırması ile iki tahmin yapılır. Bu iki tahmin arasındaki fark, CFG olarak adlandırılır.</p>

<p>Ayrıca <strong>Super-resolution, Inpainting ve Depth to Image</strong> gibi farklı koşullandırmalar da vardır. Super-resolution, fotoğrafın yüksek çözünürlüklü hali ve düşük çözünürlüklü hali üzerinde eğitim gerçekleştirilirken; depth to image, görüntünün kendisi ve derinlik haritası ile koşullandırılarak eğitilir.</p>

<h3>Kapanış</h3>

<p>Bu yazımı kapatırken, üretken sanatın ne tamamen geleneksel anlamda bir sanat olduğunu ne de sadece bir programlama disiplini olduğunu belirtmem gerekiyor. Aslında bu, hem ikisi hem de hiçbiri olarak tanımlanabilir. Yazılım, tanım itibarıyla insan ve bilgisayar arasındaki bir iletişim arayüzüdür. Sanat ise, duygularla derinden bağlantılı bir alan olup, bu kadar duygusal bir konuyu tek bir tanımla sınırlamak hata olurdu. Üretken sanat, bu iki grift ve birbirinden farklı dünyayı bir araya getirir. Üretken yapay zeka ise buna ek olarak derin bir matematik ekler, insanı taklit eder ve gerçeklik algımızı sarsar. Bu konuda kesin bir hükme varmak için henüz çok erken. Üretken sanat, sanat ve teknolojinin kesiştiği, sürekli evrilen ve sınırları zorlayan bir alandır.</p>

    </main>
    <footer>
      <span>&copy; 2024 Mert Cobanov. All rights reserved.</span>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
    <script src="/main.js"></script>
  </body>
</html>
